{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ling Thang Midterm Version 1: Iris Dataset\n",
    "\n",
    "## CS3210 - Machine Learning\n",
    "### Instructor: Dr. Feng Jiang\n",
    "### Due Date: 3/24/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.svm as svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score,  recall_score, auc,roc_curve,accuracy_score,f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the iris dataset from the Pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('iris.csv')\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying Raw Data and some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      sepal.length  sepal.width  petal.length  petal.width    variety\n",
      "0             5.1          3.5           1.4          0.2     Setosa\n",
      "1             4.9          3.0           1.4          0.2     Setosa\n",
      "2             4.7          3.2           1.3          0.2     Setosa\n",
      "3             4.6          3.1           1.5          0.2     Setosa\n",
      "4             5.0          3.6           1.4          0.2     Setosa\n",
      "..            ...          ...           ...          ...        ...\n",
      "145           6.7          3.0           5.2          2.3  Virginica\n",
      "146           6.3          2.5           5.0          1.9  Virginica\n",
      "147           6.5          3.0           5.2          2.0  Virginica\n",
      "148           6.2          3.4           5.4          2.3  Virginica\n",
      "149           5.9          3.0           5.1          1.8  Virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sepal.length  sepal.width  petal.length  petal.width variety\n",
       "count     150.000000   150.000000    150.000000   150.000000     150\n",
       "unique           NaN          NaN           NaN          NaN       3\n",
       "top              NaN          NaN           NaN          NaN  Setosa\n",
       "freq             NaN          NaN           NaN          NaN      50\n",
       "mean        5.843333     3.057333      3.758000     1.199333     NaN\n",
       "std         0.828066     0.435866      1.765298     0.762238     NaN\n",
       "min         4.300000     2.000000      1.000000     0.100000     NaN\n",
       "25%         5.100000     2.800000      1.600000     0.300000     NaN\n",
       "50%         5.800000     3.000000      4.350000     1.300000     NaN\n",
       "75%         6.400000     3.300000      5.100000     1.800000     NaN\n",
       "max         7.900000     4.400000      6.900000     2.500000     NaN"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the original dataset before encoding variety\n",
    "print(\"\\n\",df.head(150))\n",
    "\n",
    "# Generate descriptive statistics of Iris dataset\n",
    "df.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting string labels to numerical labels\n",
    "\n",
    "replacing the target labels with numerical labels using the `replace` function from the Pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      sepal.length  sepal.width  petal.length  petal.width  variety\n",
      "0             5.1          3.5           1.4          0.2        0\n",
      "1             4.9          3.0           1.4          0.2        0\n",
      "2             4.7          3.2           1.3          0.2        0\n",
      "3             4.6          3.1           1.5          0.2        0\n",
      "4             5.0          3.6           1.4          0.2        0\n",
      "..            ...          ...           ...          ...      ...\n",
      "145           6.7          3.0           5.2          2.3        2\n",
      "146           6.3          2.5           5.0          1.9        2\n",
      "147           6.5          3.0           5.2          2.0        2\n",
      "148           6.2          3.4           5.4          2.3        2\n",
      "149           5.9          3.0           5.1          1.8        2\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/22/hdrqs83s5z94vp_xg1v9l_180000gn/T/ipykernel_1616/2451871182.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace({\"variety\": {\"Setosa\": 0, \"Versicolor\": 1, \"Virginica\": 2}}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df.replace({\"variety\": {\"Setosa\": 0, \"Versicolor\": 1, \"Virginica\": 2}}, inplace=True)\n",
    "print(\"\\n\",df.head(150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "#### Two separate dataframes for features and target (Variety)\n",
    "X holds the features (sepal length, sepal width, petal length, petal width)\n",
    "Y holds the target (Variety/Species)\n",
    "\n",
    "### Train_Test_Split\n",
    "#### using the train_test_split function from sklearn\n",
    "* First split the data into 80% training and 20% testing\n",
    "* Second split the training data by 0.125 to get the validation data \n",
    "\n",
    "overall you are left with `70% training`, `20% testing`, and `10% validation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape:  (105, 4) (105,)\n",
      "Validation dataset shape:  (15, 4) (15,)\n",
      "Testing dataset shape:  (30, 4) (30,)\n",
      "     sepal.length  sepal.width  petal.length  petal.width  variety\n",
      "11            4.8          3.4           1.6          0.2        0\n",
      "4             5.0          3.6           1.4          0.2        0\n",
      "93            5.0          2.3           3.3          1.0        1\n",
      "130           7.4          2.8           6.1          1.9        2\n",
      "97            6.2          2.9           4.3          1.3        1\n"
     ]
    }
   ],
   "source": [
    "#  70% for training, 20% for testing, and 10% for validation\n",
    "X = df.drop(columns=['variety'])\n",
    "y = df['variety']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=21)\n",
    "\n",
    "# print the shape of the training, validation and testing datasets\n",
    "print(\"Training dataset shape: \", X_train.shape, y_train.shape)  \n",
    "print(\"Validation dataset shape: \", X_val.shape, y_val.shape)\n",
    "print(\"Testing dataset shape: \", X_test.shape, y_test.shape)\n",
    "\n",
    "# print the first 5 rows of the training dataset\n",
    "print(pd.concat([X_train.head(), y_train.head()], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate_Performance(Model, Xtrain, Xtest, Ytrain, Ytest) : \n",
    "    Model.fit(Xtrain,Ytrain)\n",
    "    overall_score = cross_val_score(Model, Xtrain,Ytrain, cv=10)\n",
    "    model_score = np.average(overall_score)\n",
    "    Ypredicted = Model.predict(Xtest)\n",
    "    avg = 'weighted'\n",
    "    print(f\" • Cross Validation Score : {round(model_score * 100,2)}\")\n",
    "    print(f\" • Testing Accuracy Score : {round(accuracy_score(Ytest, Ypredicted) * 100,2)}\")\n",
    "    print(f\" • Precision Score is : {np.round(precision_score(Ytest, Ypredicted , average=avg) * 100,2)}\")\n",
    "    print(f\" • Recall Score is : {np.round(recall_score(Ytest, Ypredicted , average=avg) * 100,2)}\")\n",
    "    print(f\" • F1-Score Score is : {np.round(f1_score(Ytest, Ypredicted , average=avg) * 100,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression - liblinear - 100 its:\n",
      " • Cross Validation Score : 96.09\n",
      " • Testing Accuracy Score : 96.67\n",
      " • Precision Score is : 97.08\n",
      " • Recall Score is : 96.67\n",
      " • F1-Score Score is : 96.71\n",
      "\n",
      "Logistic Regression - liblinear - 1000 its:\n",
      " • Cross Validation Score : 96.09\n",
      " • Testing Accuracy Score : 96.67\n",
      " • Precision Score is : 97.08\n",
      " • Recall Score is : 96.67\n",
      " • F1-Score Score is : 96.71\n",
      "\n",
      "Logistic Regression - lbfgs - 100 its:\n",
      " • Cross Validation Score : 98.09\n",
      " • Testing Accuracy Score : 93.33\n",
      " • Precision Score is : 94.81\n",
      " • Recall Score is : 93.33\n",
      " • F1-Score Score is : 93.45\n",
      "\n",
      "Logistic Regression - lbfgs - 1000 its:\n",
      " • Cross Validation Score : 98.09\n",
      " • Testing Accuracy Score : 93.33\n",
      " • Precision Score is : 94.81\n",
      " • Recall Score is : 93.33\n",
      " • F1-Score Score is : 93.45\n"
     ]
    }
   ],
   "source": [
    "# logreg with liblinear solver 100 iterations\n",
    "logReg_liblinear_100 = LogisticRegression(solver='liblinear', multi_class='auto', max_iter=100)\n",
    "logReg_liblinear_100.fit(X_train, y_train)\n",
    "y_pred_LR_liblinear_100 = logReg_liblinear_100.predict(X_test)\n",
    "print(\"\\nLogistic Regression - liblinear - 100 its:\")\n",
    "Evaluate_Performance(logReg_liblinear_100, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# logreg with liblinear solver 1000 iterations\n",
    "logReg_liblinear_1000 = LogisticRegression(solver='liblinear', multi_class='auto', max_iter=1000)\n",
    "logReg_liblinear_1000.fit(X_train, y_train)\n",
    "y_pred_LR_liblinear_1000 = logReg_liblinear_1000.predict(X_test)\n",
    "print(\"\\nLogistic Regression - liblinear - 1000 its:\")\n",
    "Evaluate_Performance(logReg_liblinear_1000, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# logreg with lbfgs solver 100 iterations\n",
    "logReg_lbfgs_100 = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=100)\n",
    "logReg_lbfgs_100.fit(X_train, y_train)\n",
    "y_pred_LR_lbfgs_100 = logReg_lbfgs_100.predict(X_test)\n",
    "print(\"\\nLogistic Regression - lbfgs - 100 its:\")\n",
    "Evaluate_Performance(logReg_lbfgs_100, X_train, X_test, y_train, y_test) \n",
    "\n",
    "# logreg with lbfgs solver 1000 iterations\n",
    "logReg_lbfgs_1000 = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000)\n",
    "logReg_lbfgs_1000.fit(X_train, y_train)\n",
    "y_pred_LR_lbfgs_1000 = logReg_lbfgs_1000.predict(X_test)\n",
    "print(\"\\nLogistic Regression - lbfgs - 1000 its:\")\n",
    "Evaluate_Performance(logReg_lbfgs_1000, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Evaluation\n",
    "\n",
    "### Liblinear vs LBFGS\n",
    "from the results, we can see that the `liblinear` solver is better than the `lbfgs` solver\n",
    "\n",
    "regardless of the iteration, the `liblinear` solver has a higher accuracy score than the `lbfgs` solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine linear:\n",
      " • Cross Validation Score : 98.09\n",
      " • Testing Accuracy Score : 96.67\n",
      " • Precision Score is : 97.08\n",
      " • Recall Score is : 96.67\n",
      " • F1-Score Score is : 96.71\n",
      "\n",
      "SVM with RBF kernel:\n",
      " • Cross Validation Score : 99.0\n",
      " • Testing Accuracy Score : 90.0\n",
      " • Precision Score is : 90.53\n",
      " • Recall Score is : 90.0\n",
      " • F1-Score Score is : 90.12\n",
      "\n",
      "SVM with polynomial kernel:\n",
      " • Cross Validation Score : 97.09\n",
      " • Testing Accuracy Score : 93.33\n",
      " • Precision Score is : 94.81\n",
      " • Recall Score is : 93.33\n",
      " • F1-Score Score is : 93.45\n"
     ]
    }
   ],
   "source": [
    "# SVM with linear kernel\n",
    "svm_linear = svm.SVC(kernel='linear')\n",
    "svm_linear.fit(X_train, y_train)\n",
    "y_pred_SVM = svm_linear.predict(X_test)\n",
    "print(\"Support Vector Machine linear:\")\n",
    "Evaluate_Performance(svm_linear, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# SVM with RBF kernel\n",
    "svm_rbf = svm.SVC(kernel='rbf')\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "y_pred_SVM_rbf = svm_rbf.predict(X_test)\n",
    "print(\"\\nSVM with RBF kernel:\")\n",
    "Evaluate_Performance(svm_rbf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# SVC with polynomial kernel\n",
    "svm_poly = svm.SVC(kernel='poly')\n",
    "svm_poly.fit(X_train, y_train)\n",
    "y_pred_SVM_poly = svm_poly.predict(X_test)\n",
    "print(\"\\nSVM with polynomial kernel:\")\n",
    "Evaluate_Performance(svm_poly, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Evaluation\n",
    "\n",
    "### Linear vs RBF\n",
    "in terms of testing accuracy, precision, recall, and f1-score, the `linear` kernel is better than the both the `rbf` and `poly` kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Max Depth 1:\n",
      " • Cross Validation Score : 62.82\n",
      " • Testing Accuracy Score : 60.0\n",
      " • Precision Score is : 45.26\n",
      " • Recall Score is : 60.0\n",
      " • F1-Score Score is : 49.23\n",
      "\n",
      "Decision Tree Max Depth 2:\n",
      " • Cross Validation Score : 95.18\n",
      " • Testing Accuracy Score : 83.33\n",
      " • Precision Score is : 82.99\n",
      " • Recall Score is : 83.33\n",
      " • F1-Score Score is : 83.03\n",
      "\n",
      "Decision Tree Max Depth 3:\n",
      " • Cross Validation Score : 97.09\n",
      " • Testing Accuracy Score : 93.33\n",
      " • Precision Score is : 94.81\n",
      " • Recall Score is : 93.33\n",
      " • F1-Score Score is : 93.45\n",
      "\n",
      "Decision Tree Max Depth 5:\n",
      " • Cross Validation Score : 98.09\n",
      " • Testing Accuracy Score : 93.33\n",
      " • Precision Score is : 94.81\n",
      " • Recall Score is : 93.33\n",
      " • F1-Score Score is : 93.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "DecTree1 = DecisionTreeClassifier(max_depth=1, random_state=25)\n",
    "DecTree1 = DecTree1.fit(X_train, y_train)\n",
    "y_pred_DT = DecTree1.predict(X_test)\n",
    "print(\"Decision Tree Max Depth 1:\")\n",
    "Evaluate_Performance(DecTree1, X_train, X_test, y_train, y_test)\n",
    "\n",
    "DecTree2 = DecisionTreeClassifier(max_depth=2, random_state=25)\n",
    "DecTree2 = DecTree2.fit(X_train, y_train)\n",
    "y_pred_DT = DecTree2.predict(X_test)\n",
    "print(\"\\nDecision Tree Max Depth 2:\")\n",
    "Evaluate_Performance(DecTree2, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Depth of 3 which is appropriate for the Iris dataset\n",
    "DecTree3 = DecisionTreeClassifier(max_depth=3, random_state=25)\n",
    "DecTree3 = DecTree3.fit(X_train, y_train)\n",
    "y_pred_DT = DecTree3.predict(X_test)\n",
    "print(\"\\nDecision Tree Max Depth 3:\")\n",
    "Evaluate_Performance(DecTree3, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Depth 5 for overall performance\n",
    "DecTree = DecisionTreeClassifier(max_depth=5, random_state=25)\n",
    "DecTree = DecTree.fit(X_train, y_train)\n",
    "y_pred_DT = DecTree.predict(X_test)\n",
    "print(\"\\nDecision Tree Max Depth 5:\")\n",
    "Evaluate_Performance(DecTree, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Evaluation\n",
    "\n",
    "### Tree Depth Analysis \n",
    "\n",
    "Of the 4 different tree depths, the tree depth of 5 has the highest accuracy score of 93.33\n",
    "\n",
    "However after the a depth of 3 the increase in all other metrics is minimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Evaluations\n",
    "\n",
    "In this notebook, I have implemented three different classification tools. \n",
    "- Logistic Regression\n",
    "- Support Vector Machine\n",
    "- Decision Tree\n",
    "\n",
    "Each of the the models are trained and tested on the Iris dataset (Canvas Files). The models are evaluated using the accuracy score. \n",
    "\n",
    "In each of the test cases for the models, I also experimented with different hyperparameters to see if the accuracy score can be improved.\n",
    "\n",
    "##### Different hyperparameters for each model\n",
    "* Logistic Regression:\n",
    "\n",
    "    - Experimented with two different solvers: `liblinear` and `lbfgs`\n",
    "\n",
    "    - Each solver had two different iterations: `100` and `1000`\n",
    "\n",
    "* Support Vector Machine:\n",
    "    - Experimented with three different kernels: `linear`, `poly`, and `rbf`\n",
    "\n",
    "* Decision Tree:\n",
    "    - Experiment with depth of the tree: `1`, `2`, `3`, and standard `30`\n",
    "\n",
    "### **Reference their respective cell blocks for the result and analysis**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for testing accuracy score: logReg_liblinear_100\n",
      "Best score: 96.67\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store the models and scores\n",
    "model_scores = {\n",
    "    'logReg_liblinear_100': accuracy_score(y_test, logReg_liblinear_100.predict(X_test)),\n",
    "    'logReg_liblinear_1000': accuracy_score(y_test, logReg_liblinear_1000.predict(X_test)),\n",
    "    'logReg_lbfgs_100': accuracy_score(y_test, logReg_lbfgs_100.predict(X_test)),\n",
    "    'logReg_lbfgs_1000': accuracy_score(y_test, logReg_lbfgs_1000.predict(X_test)),\n",
    "    'svm_linear': accuracy_score(y_test, svm_linear.predict(X_test)),\n",
    "    'svm_rbf': accuracy_score(y_test, svm_rbf.predict(X_test)),\n",
    "    'svm_poly': accuracy_score(y_test, svm_poly.predict(X_test)),\n",
    "    'DecTree1': accuracy_score(y_test, DecTree1.predict(X_test)),\n",
    "    'DecTree2': accuracy_score(y_test, DecTree2.predict(X_test)),\n",
    "    'DecTree3': accuracy_score(y_test, DecTree3.predict(X_test)),\n",
    "    'DecTree': accuracy_score(y_test, DecTree.predict(X_test))\n",
    "}\n",
    "\n",
    "# Find the best model and score\n",
    "best_model = max(model_scores, key=model_scores.get)\n",
    "best_score = np.round(model_scores[best_model] * 100, 2)\n",
    "\n",
    "# Print the best model and score\n",
    "print(\"Best model for testing accuracy score:\", best_model)\n",
    "print(\"Best score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Thoughts\n",
    "\n",
    "##### Based on the provided performance metrics, the best model appears to be Logistic Regression with liblinear solver and 100 or 1000 regularization strength\n",
    "\n",
    "Both models achieve the highest testing accuracy score of 96.67% among all models\n",
    "\n",
    "The precision, recall, and F1-score are also high and consistent across both models, indicating good overall performance\n",
    "\n",
    "These models also have a relatively high training accuracy score and cross-validation score, indicating good generalization and performance on unseen data\n",
    "\n",
    "While the SVM with a linear kernel also achieves the same testing accuracy score of 96.67%, the logistic regression models have slightly higher precision, recall, and F1-scores, making them preferable choices\n",
    "\n",
    "Therefore, based on the provided information, the Logistic Regression with liblinear solver and 100 or 1000 regularization strength is considered the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus: Data Augmentation (Noise)\n",
    "##### Creating noise in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression - liblinear - 100 its with noise:\n",
      " • Cross Validation Score : 92.27\n",
      " • Testing Accuracy Score : 93.33\n",
      " • Precision Score is : 94.81\n",
      " • Recall Score is : 93.33\n",
      " • F1-Score Score is : 93.45\n",
      "\n",
      "Support Vector Machine with noise:\n",
      " • Cross Validation Score : 98.0\n",
      " • Testing Accuracy Score : 90.0\n",
      " • Precision Score is : 90.53\n",
      " • Recall Score is : 90.0\n",
      " • F1-Score Score is : 90.12\n",
      "\n",
      "Decision Tree Max Depth 3 with noise:\n",
      " • Cross Validation Score : 95.18\n",
      " • Testing Accuracy Score : 93.33\n",
      " • Precision Score is : 94.81\n",
      " • Recall Score is : 93.33\n",
      " • F1-Score Score is : 93.45\n"
     ]
    }
   ],
   "source": [
    "# create random noise for the iris dataset\n",
    "np.random.seed(21)\n",
    "X_noise = X + np.random.normal(0, 0.1, X.shape)\n",
    "X_train_noise, X_test_noise, y_train_noise, y_test_noise = train_test_split(X_noise, y, test_size=0.2, random_state=21)\n",
    "X_train_noise, X_val_noise, y_train_noise, y_val_noise = train_test_split(X_train_noise, y_train_noise, test_size=0.125, random_state=21)\n",
    "\n",
    "# Logistic Regression with liblinear solver 100 iterations\n",
    "logReg_liblinear_100_noise = LogisticRegression(solver='liblinear', multi_class='auto', max_iter=100)\n",
    "logReg_liblinear_100_noise.fit(X_train_noise, y_train_noise)\n",
    "y_pred_LR_liblinear_100_noise = logReg_liblinear_100_noise.predict(X_test_noise)\n",
    "print(\"\\nLogistic Regression - liblinear - 100 its with noise:\")\n",
    "Evaluate_Performance(logReg_liblinear_100_noise, X_train_noise, X_test_noise, y_train_noise, y_test_noise)\n",
    "\n",
    "# SVM with linear kernel\n",
    "svm_linear_noise = svm.SVC(kernel='linear')\n",
    "svm_linear_noise.fit(X_train_noise, y_train_noise)\n",
    "y_pred_SVM_noise = svm_linear_noise.predict(X_test_noise)\n",
    "print(\"\\nSupport Vector Machine with noise:\")\n",
    "Evaluate_Performance(svm_linear_noise, X_train_noise, X_test_noise, y_train_noise, y_test_noise)\n",
    "\n",
    "# Decision Tree with max depth 3\n",
    "DecTree3_noise = DecisionTreeClassifier(max_depth=3)\n",
    "DecTree3_noise = DecTree3_noise.fit(X_train_noise, y_train_noise)\n",
    "y_pred_DT_noise = DecTree3_noise.predict(X_test_noise)\n",
    "print(\"\\nDecision Tree Max Depth 3 with noise:\")\n",
    "Evaluate_Performance(DecTree3_noise, X_train_noise, X_test_noise, y_train_noise, y_test_noise)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation Explanation\n",
    "\n",
    "Creating noise in the dataset by adding random noise to features using the `random.normal` function from the numpy library\n",
    "\n",
    "Augmenting the training data by adding noise to the features allows the model to generalize better and improve performance\n",
    "\n",
    "This creates a more robust model especially when the model is trained on a small dataset with repetitive patterns, which can lead to overfitting\n",
    "\n",
    "**minimal difference in the accuracy score between the original and augmented datasets**\n",
    "\n",
    "###### **Alternatively, increasing the number of samples in the dataset can also improve the model's performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
